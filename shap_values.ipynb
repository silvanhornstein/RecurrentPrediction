{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5d0c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import shap\n",
    "import gensim.models.word2vec\n",
    "import gensim\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cce382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Import, train-testsplit and Outcome.\n",
    "\n",
    "data = pd.read_csv(\"anonymized_data_final_sep.csv\")\n",
    "data[\"recc\"] = np.where(data.timediff <= 188, 1, 0)\n",
    "traindata = data[data.train==\"train\"]\n",
    "testdata = data[data.train==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorize the text bodies of the training data and convert it to a DataFrame. \n",
    "#Suffix of each column indicates whether the word was used by counselor or chatter\n",
    "\n",
    "vectorizerchatter = TfidfVectorizer(max_df=0.8, \n",
    "                                    min_df=150, \n",
    "                                    use_idf=False)\n",
    "vectorizercouns = TfidfVectorizer(max_df=0.3, \n",
    "                                  min_df=75, \n",
    "                                  use_idf=False)\n",
    "\n",
    "X_trainchat = vectorizerchatter.fit_transform(traindata[\"body_chat\"])\n",
    "X_trainchatdata = pd.DataFrame(X_trainchat.toarray())\n",
    "X_trainchatdata.columns = vectorizerchatter.get_feature_names_out() \n",
    "X_trainchatdata = X_trainchatdata.add_suffix(\"_chat\")\n",
    "\n",
    "X_traincouns = vectorizercouns.fit_transform(traindata[\"body_couns\"])\n",
    "X_traincounsdata = pd.DataFrame(X_traincouns.toarray())\n",
    "X_traincounsdata.columns = vectorizercouns.get_feature_names_out() \n",
    "X_traincounsdata = X_traincounsdata.add_suffix(\"_couns\")\n",
    "\n",
    "X_train = pd.concat([X_trainchatdata,\n",
    "                     X_traincounsdata],\n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2149fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the classifier on the training data \n",
    "\n",
    "classi = XGBClassifier(colsample_bytree=0.9, \n",
    "                       eta=0.05, \n",
    "                       gamma=1.5, \n",
    "                       max_depth=8, \n",
    "                       min_child_weight=20, \n",
    "                       subsample=0.6)\n",
    "\n",
    "classi.fit(X_train, traindata[\"recc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c97c5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the test dataset\n",
    "\n",
    "X_testchat = vectorizerchatter.transform(testdata[\"body_chat\"])\n",
    "X_testcouns = vectorizercouns.transform(testdata[\"body_couns\"])\n",
    "\n",
    "X_testchatdata = pd.DataFrame(X_testchat.toarray())\n",
    "X_testchatdata.columns = vectorizerchatter.get_feature_names_out() \n",
    "\n",
    "X_testcounsdata = pd.DataFrame(X_testcouns.toarray())\n",
    "X_testcounsdata.columns = vectorizercouns.get_feature_names_out() \n",
    "\n",
    "X_testchatdata = X_testchatdata.add_suffix(\"_chat\")\n",
    "X_testcounsdata = X_testcounsdata.add_suffix(\"_couns\")\n",
    "\n",
    "X_test = pd.concat([X_testchatdata,X_testcounsdata],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcf388c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Run shap explainer on the test dataset\n",
    "\n",
    "explainer = shap.TreeExplainer(classi)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap_data = pd.DataFrame(shap_values, \n",
    "                         columns=X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c3b603",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename columns (German to English)\n",
    "\n",
    "X_test = X_test.rename(columns={\"tagsub_couns\" : \"Daytime (CO)\", \"morgen_chat\" : \"Tommorow (CH)\",\n",
    "                   \"nacht_chat\" : \"Night (CH)\", \"männlich_chat\" : \"Male (CH)\",\n",
    "                   \"12_chat\" : \"12 (CH)\", \"13_chat\" : \"13 (CH)\",\n",
    "                   \"verletz_couns\" : \"Harm (CO)\", \"verletzt_couns\" : \"Harmed (CO)\",\n",
    "                   \"rat_chat\" : \"Advice (CH)\", \"anspann_couns\" : \"Tension (CH)\"})\n",
    "shap_data = shap_data.rename(columns= {\"tagsub_couns\" : \"Daytime (CO)\", \"morgen_chat\" : \"Tommorow (CH)\",\n",
    "                   \"nacht_chat\" : \"Night (CH)\", \"männlich_chat\" : \"Male (CH)\",\n",
    "                   \"12_chat\" : \"12 (CH)\", \"13_chat\" : \"13 (CH)\",\n",
    "                   \"verletz_couns\" : \"Harm (CO)\", \"verletzt_couns\" : \"Harmed (CO)\",\n",
    "                   \"rat_chat\" : \"Advice (CH)\", \"anspann_couns\" : \"Tension (CH)\"})\n",
    "shap.summary_plot(shap_data.to_numpy(),\n",
    "                  X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc8efb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Shap plot for 20 Selected Variables\n",
    "\n",
    "columns = [\"Daytime (CO)\", \"Tommorow (CH)\", \"Night (CO)\", \"Male (CH)\",\n",
    "           \"12 (CH)\", \"13 (CH)\", \"Harm (CO)\", \"Harmed (CO)\",\n",
    "           \"Advice (CH)\", \"Tension (CH)\", \"Friend/Girlfriend (CH)\", \"Girl (CH)\",\n",
    "           \"Child (CO)\", \"Internet Care (CO)\", \"Professional (CO)\", \"Job (CH)\",\n",
    "           \"Suicide(CO)\", \"Dying (CH)\", \"Work (CH)\", \"Everyday Life (CH)\",\n",
    "           \"14 (CH)\", \"Spot for Therapy (CO)\", \"Suicide (CO)\", \"Cutting (CH)\"]\n",
    "\n",
    "X_test = X_test[columns]\n",
    "shap_data = shap_data[columns]\n",
    "\n",
    "shap.summary_plot(shap_data.to_numpy(),\n",
    "                  X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clustering: Loading Word2Vec Model (Source: https://github.com/devmount/GermanWordEmbeddings)\n",
    "\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('\\german.model', binary=True)\n",
    "chatdata_words = vectorizerchatter.get_feature_names_out()\n",
    "counsdata_words = vectorizercouns.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7411f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining chatters and counselors word for clustering.\n",
    "\n",
    "words_combined = np.union1d(chatdata_words, counsdata_words)\n",
    "out = []\n",
    "wor = []\n",
    "\n",
    "for word in words_combined:\n",
    "    try:\n",
    "        out.append(model[word])\n",
    "        wor.append(word)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20f8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sillhouete Scores for the Clusters.\n",
    "\n",
    "sse = []\n",
    "silhouette_avg = []\n",
    "\n",
    "for k in range(2, 30):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(out)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    cluster_labels = kmeans.labels_\n",
    "    silhouette_avg.append(silhouette_score(out, cluster_labels))\n",
    "\n",
    "plt.plot(range(2,30), sse)\n",
    "plt.title(\"Elbow Curve\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(2,30),silhouette_avg)\n",
    "plt.title(\"Silhouette Scores for k Clusters\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the clusters using KMeans and the identified number of clusters.\n",
    "\n",
    "kmeans = KMeans(n_clusters=20)\n",
    "kmeans.fit(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af437de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the clusters for the Word Stems.\n",
    "\n",
    "worddata = pd.DataFrame({\"word\": wor})\n",
    "worddata[\"pred\"] = kmeans.predict(out)\n",
    "worddata.groupby(\"pred\").count().reset_index().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33d388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building final dataset\n",
    "\n",
    "cluster = []\n",
    "values = []\n",
    "words = []\n",
    "clustersize = []\n",
    "worddata = pd.DataFrame({\"word\": wor})\n",
    "worddata[\"pred\"] = kmeans.predict(out)\n",
    "\n",
    "chatter_shap = shap_data.filter(regex='_chat')\n",
    "chatter_shap.columns = chatter_shap.columns.str.replace('_chat', '')\n",
    "\n",
    "couns_shap = shap_data.filter(regex='_couns')\n",
    "couns_shap.columns = couns_shap.columns.str.replace('_couns', '')\n",
    "\n",
    "for i in range(0,20):\n",
    "    cluster.append(i)\n",
    "    words.append(worddata[worddata.pred == i].word.values)\n",
    "    clustersize.append(len(worddata[worddata.pred == i].word.values))\n",
    "    values.append(chatter_shap.filter(worddata[worddata.pred == i].word.values).abs().sum().sum() + couns_shap.filter(worddata[worddata.pred == 0].word.values).abs().sum().sum())\n",
    "\n",
    "data = pd.DataFrame({\"cluster\":cluster, \n",
    "                     \"value\":values, \n",
    "                     \"words\":words, \n",
    "                     \"clustersize\":clustersize})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
